{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from pyvis.network import Network\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_df() -> pd.DataFrame:\n",
    "    df = pd.read_csv('./data/faculty_data_final.csv', encoding='ISO-8859-1')\n",
    "\n",
    "    df = df.rename(\n",
    "            columns={\n",
    "                'Name': 'name',\n",
    "                'School': \"school\",\n",
    "                'Degree Program': \"degree_program\",\n",
    "                'UGA Affiliations (e.g. Centers or Institutes etc.)': \"uga_affiliations\",\n",
    "                'Previous Instutution(s)': \"previous_institutions\",\n",
    "                'PhD. Degree': \"phd_degree\",\n",
    "                'Interdisciplinary Areas': \"interdisciplinary_areas\",\n",
    "                'Broad Speacialty Areas / Expertise': \"broad_specialties\",\n",
    "                'Overlapping Expertise': \"overlapping_expertise\",\n",
    "                'Research Keywords': \"research_keywords\",\n",
    "                'Major Tool / Equipment': \"equipment\",\n",
    "                'Potential Sponsors': \"potential_sponsors\",\n",
    "                'UGA Collaborator(s)': \"uga_collaborators\",\n",
    "                'Outside Collaborator(s)': \"outside_collaborators\",\n",
    "                'Global Engagement': \"global_engagement\",\n",
    "                'Memberships': \"memberships\",\n",
    "                'Other Information': \"other\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df['name'] = df['name'].ffill()\n",
    "    df['name'] = df['name'].str.strip()\n",
    "    df = df.groupby('name').agg(lambda x: ', '.join(x.dropna().astype(str)))\n",
    "\n",
    "    def combine_entries(series):\n",
    "        if series.dtype == 'object':\n",
    "            return ', '.join(set(', '.join(series.dropna()).split(', ')))\n",
    "        else:\n",
    "            return series.dropna().iloc[0]\n",
    "\n",
    "    df = df.groupby('name').agg(combine_entries).reset_index()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = initialize_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_columns(df) -> pd.DataFrame:\n",
    "    gen_df = df[[\"name\", \"interdisciplinary_areas\", \"broad_specialties\", \"outside_collaborators\"]]\n",
    "    json_data = gen_df.to_json(orient=\"records\", indent=4)\n",
    "\n",
    "    API_KEY = os.getenv(\"API_KEY\")\n",
    "\n",
    "    client = OpenAI(\n",
    "        api_key=API_KEY\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        You are categorizing engineering professors at the University of Georgia based on their interdisciplinary research areas and broad specialties.\n",
    "\n",
    "        ## **Task Requirements**\n",
    "        1. **You must group all professors into exactly 4-5 broad categories.**  \n",
    "           - Example categories:  \n",
    "               - \"AI, Data Science, and Cyber-Physical Systems\"  \n",
    "               - \"Biomedical and Health Engineering\"  \n",
    "               - \"Energy, Environment, and Sustainability\"  \n",
    "               - \"Materials, Manufacturing, and Robotics\"  \n",
    "               - \"Education, Policy, and Social Impact in Engineering\"  \n",
    "           - **Categories must remain broad and standardized** while maintaining meaningful research connections.  \n",
    "           - You may **slightly adjust** the names but **must not exceed 5 groups**.  \n",
    "\n",
    "        2. **Strict Assignment Rules:**  \n",
    "           - **Every professor must be assigned to one and only one category.**  \n",
    "           - If a professor's research spans multiple areas, **assign them to the closest matching category.**  \n",
    "           - If a professor's research data is completely empty, assign them `\"\"` (empty string).  \n",
    "\n",
    "        3. **Category Balance Enforcement:**  \n",
    "           - If a category has **only one professor**, merge it with the most related category.  \n",
    "           - If a category has an excessive number of professors, **split only if absolutely necessary** (and still ensure a max of 5 groups).  \n",
    "           - The **final output must always contain 4-5 categories**, no more, no less.  \n",
    "\n",
    "        4. **STRICT JSON Output Format:**  \n",
    "           Your response **MUST BE STRICTLY JSON** and match the format below:  \n",
    "        ```json\n",
    "        {{\n",
    "            \"insight\": \"Some professors had highly interdisciplinary research, requiring careful classification.\",\n",
    "            \"generated_disciplines\": [\n",
    "                {{\n",
    "                    \"name\": \"Professor A\",\n",
    "                    \"discipline\": \"AI, Data Science, and Cyber-Physical Systems\"\n",
    "                }},\n",
    "                {{\n",
    "                    \"name\": \"Professor B\",\n",
    "                    \"discipline\": \"Biomedical and Health Engineering\"\n",
    "                }},\n",
    "                {{\n",
    "                    \"name\": \"Professor C\",\n",
    "                    \"discipline\": \"Materials, Manufacturing, and Robotics\"\n",
    "                }},\n",
    "                ...\n",
    "            ]\n",
    "        }}\n",
    "        ```\n",
    "\n",
    "        **Deviating from this format will be considered incorrect output.**  \n",
    "\n",
    "        ## **Input JSON Data**\n",
    "        ```json\n",
    "        {json_data}\n",
    "        ```\n",
    "    \"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        store=True,\n",
    "        messages=[{\n",
    "            \"role\": \"user\", \n",
    "            \"content\": prompt\n",
    "        }]\n",
    "    )\n",
    "\n",
    "    raw_content = completion.choices[0].message.content.strip()\n",
    "\n",
    "    if raw_content.startswith(\"```json\"):\n",
    "        raw_content = raw_content[7:-3]\n",
    "\n",
    "    data = json.loads(raw_content)\n",
    "    disciplines_df = pd.DataFrame(data[\"generated_disciplines\"])\n",
    "    disciplines_df.set_index(\"name\", inplace=True)\n",
    "    disciplines_df.index = disciplines_df.index.str.strip()\n",
    "    \n",
    "    df_json = df.to_json(orient=\"records\", indent=4)\n",
    "    second_prompt = f\"\"\"\n",
    "        You are tasked with categorizing engineering professors at the University of Georgia based on their **relatedness to other professors**. Your goal is to **group professors into strictly defined clusters** based on shared collaborators, research areas, disciplines, and institutional affiliations.\n",
    "\n",
    "        ## **Instructions**\n",
    "        1. **You must calculate connection strength using only the following columns:**\n",
    "            - **'uga_collaborators'** (Shared UGA collaborators)\n",
    "            - **'outside_collaborators'** (Shared external collaborators)\n",
    "            - **'interdisciplinary_areas'** (Shared interdisciplinary areas)\n",
    "            - **'broad_specialties'** (Shared broad specialties)\n",
    "            - **'generated_disciplines'** (Identical generated discipline)\n",
    "            - **'overlapping_expertise'** (Number of overlapping expertise)\n",
    "            - **'current_affiliation'** (Same or highly related affiliation)\n",
    "            - **'school'** (Same or highly related school)\n",
    "\n",
    "        2. **Connection weights MUST be assigned using the following STRICT formula:**\n",
    "            - **Overlapping Expertise (Weight: 3 per shared expertise)** → Example: If two professors share 2 overlapping expertise areas, weight = **6.0**.\n",
    "            - **Shared UGA Collaborators (Weight: 2 per collaborator)** → Example: If two professors share 3 UGA collaborators, weight = **6.0**.\n",
    "            - **Shared Outside Collaborators (Weight: 1.5 per collaborator)** → Example: If two professors share 3 outside collaborators, weight = **4.5**.\n",
    "            - **Shared Interdisciplinary Areas (Weight: 1 per area)** → Example: If two professors share 2 interdisciplinary areas, weight = **2.0**.\n",
    "            - **Shared Broad Specialties (Weight: 1 per specialty)** → Example: If two professors share 3 broad specialties, weight = **3.0**.\n",
    "            - **Same Generated Discipline (Weight: 2 if True, 0 if False)**.\n",
    "            - **Same Current Affiliation / Degree Program (Weight: 0.5 if True, 0 if False)**.\n",
    "            - **Same School (Weight: 0.3 if True, 0 if False)**.\n",
    "            - **TOTAL connection strength is the sum of all applicable weights. The final value MUST be rounded to one decimal place.**\n",
    "\n",
    "        3. **Ensure consistency in reasoning by explicitly listing column contributions for each connection.**  \n",
    "        **Do NOT generate random relationships**—only professors with nonzero connection weight should be included in the output.\n",
    "\n",
    "        ## **Example of the Required JSON Output Format**\n",
    "        Your response **MUST ONLY** be a JSON object in this format:\n",
    "        ```json\n",
    "        {{\n",
    "            \"insight\": \"Some professors had no strong connections due to lack of collaborators or overlapping expertise.\",\n",
    "            \"generated_groups\": [\n",
    "                {{\n",
    "                    \"name\": \"Professor A\",\n",
    "                    \"related_professors\": [\n",
    "                        {{\n",
    "                            \"name\": \"Professor B\",\n",
    "                            \"weight\": 6.5,\n",
    "                            \"reasoning\": {{\n",
    "                                \"uga_collaborators\": 2,\n",
    "                                \"outside_collaborators\": 1,\n",
    "                                \"interdisciplinary_areas\": 1,\n",
    "                                \"broad_specialties\": 0,\n",
    "                                \"generated_disciplines\": true,\n",
    "                                \"overlapping_expertise\": 0,\n",
    "                                \"current_affiliation\": false,\n",
    "                                \"school\": false\n",
    "                            }}\n",
    "                        }},\n",
    "                        {{\n",
    "                            \"name\": \"Professor C\",\n",
    "                            \"weight\": 3.0,\n",
    "                            \"reasoning\": {{\n",
    "                                \"uga_collaborators\": 0,\n",
    "                                \"outside_collaborators\": 0,\n",
    "                                \"interdisciplinary_areas\": 0,\n",
    "                                \"broad_specialties\": 0,\n",
    "                                \"generated_disciplines\": true,\n",
    "                                \"overlapping_expertise\": 0,\n",
    "                                \"current_affiliation\": false,\n",
    "                                \"school\": false\n",
    "                            }}\n",
    "                        }}\n",
    "                    ]\n",
    "                }},\n",
    "                ...\n",
    "            ]\n",
    "        }}\n",
    "        ```\n",
    "        **Failure to follow this format exactly will result in incorrect output. Do not deviate from these instructions.**\n",
    "\n",
    "        ## **Input Data**\n",
    "        ```json\n",
    "        {df_json}\n",
    "        ```\n",
    "    \"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        store=True,\n",
    "        messages=[{\n",
    "            \"role\": \"user\", \n",
    "            \"content\": second_prompt\n",
    "        }]\n",
    "    )\n",
    "    raw_content = completion.choices[0].message.content.strip()\n",
    "\n",
    "    if raw_content.startswith(\"```json\"):\n",
    "        raw_content = raw_content[7:-3]\n",
    "\n",
    "    relatedness_data = json.loads(raw_content)\n",
    "\n",
    "    relatedness_df = pd.DataFrame(relatedness_data[\"generated_groups\"])\n",
    "    print(relatedness_df)\n",
    "    relatedness_df = relatedness_df.reset_index(drop=True).set_index('name')\n",
    "\n",
    "    # Convert to tuples\n",
    "    relatedness_df[\"related_professors\"] = relatedness_df[\"related_professors\"].apply(\n",
    "        lambda x: [(rel[\"name\"], float(rel[\"weight\"])) for rel in x]\n",
    "    )\n",
    "\n",
    "    relatedness_df.index = relatedness_df.index.str.strip()\n",
    "\n",
    "    df = df.reset_index(drop=True).set_index('name')\n",
    "    df = df.merge(disciplines_df, left_index=True, right_index=True, how=\"left\")\n",
    "    df = df.merge(relatedness_df, left_index=True, right_index=True, how=\"left\")\n",
    "\n",
    "    df_exploded = df.copy()\n",
    "\n",
    "    df_exploded = df_exploded.assign(overlapping_expertise=df_exploded['overlapping_expertise'].str.split(',')).explode('overlapping_expertise')\n",
    "    df_exploded = df_exploded.assign(uga_collaborators=df_exploded['uga_collaborators'].str.split(',')).explode('uga_collaborators')\n",
    "    df_exploded = df_exploded.assign(potential_sponsors=df_exploded['potential_sponsors'].str.split(',')).explode('potential_sponsors')\n",
    "\n",
    "    df_exploded['overlapping_expertise'] = df_exploded['overlapping_expertise'].str.strip()\n",
    "    df_exploded['uga_collaborators'] = df_exploded['uga_collaborators'].str.strip()\n",
    "    df_exploded['potential_sponsors'] = df_exploded['potential_sponsors'].str.strip()\n",
    "\n",
    "    return df_exploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_graph(df, \n",
    "               search_professor=False, \n",
    "               category_search_parameter=\"degree_program\", \n",
    "               professor_search_parameter=None,\n",
    "               min_weight=0\n",
    "    ):\n",
    "    if not search_professor:\n",
    "        graphs = {}\n",
    "        miscellaneous = []  # will hold nodes from groups with only one element\n",
    "\n",
    "        # Loop over each unique group value\n",
    "        for value in df[category_search_parameter].unique():\n",
    "            if pd.isna(value) or value == \"\":\n",
    "                continue\n",
    "\n",
    "            subset = df[df[category_search_parameter] == value]\n",
    "\n",
    "            # If this category only has one node, add it to miscellaneous and skip plotting it\n",
    "            if len(subset) == 1:\n",
    "                miscellaneous.extend(list(subset.index))\n",
    "                continue\n",
    "\n",
    "            # Build a global graph based on shared expertise\n",
    "            G = nx.Graph()\n",
    "            all_nodes = df.index.unique()  # assuming the index identifies a person\n",
    "            G.add_nodes_from(all_nodes)\n",
    "\n",
    "            # Iterate over each unique expertise in the exploded column\n",
    "            for expertise in df[category_search_parameter].unique():\n",
    "                if pd.isna(expertise) or expertise == \"\":\n",
    "                    continue\n",
    "\n",
    "                # Get the unique nodes that have this expertise\n",
    "                nodes = list(df[df[category_search_parameter] == expertise].index.unique())\n",
    "\n",
    "                # For every pair of nodes sharing the expertise, add or update an edge\n",
    "                for i in range(len(nodes)):\n",
    "                    for j in range(i + 1, len(nodes)):\n",
    "                        if G.has_edge(nodes[i], nodes[j]):\n",
    "                            G[nodes[i]][nodes[j]]['weight'] += 2\n",
    "                        else:\n",
    "                            G.add_edge(nodes[i], nodes[j], weight=2)\n",
    "\n",
    "            graphs = {\"Expertise Graph\": G}\n",
    "\n",
    "        # Visualize the graphs for groups with more than one node\n",
    "        num_graphs = len(graphs)\n",
    "        cols = 2\n",
    "        rows = (num_graphs + cols - 1) // cols\n",
    "\n",
    "        plt.figure(figsize=(cols * 5, rows * 4))\n",
    "\n",
    "        for i, (value, G) in enumerate(graphs.items(), 1):\n",
    "            plt.subplot(rows, cols, i)            \n",
    "            pos = nx.spring_layout(G, k=0.2, seed=42)\n",
    "            \n",
    "            nx.draw(\n",
    "                G, pos, with_labels=True, node_color='lightblue', node_size=1500,\n",
    "                font_size=10, font_weight='normal', edge_color='gray', width=2,\n",
    "                alpha=0.7, edgecolors=\"black\"\n",
    "            )\n",
    "            plt.title(value, fontsize=12)\n",
    "\n",
    "        # Optionally, output the miscellaneous nodes (not plotted)\n",
    "        print(\"Miscellaneous nodes (grouped but not plotted):\", miscellaneous)\n",
    "\n",
    "        # Optionally, if you want to visualize one of the graphs in a network visualizer:\n",
    "        if graphs:\n",
    "            # Here we use the last graph in the dictionary\n",
    "            last_key = list(graphs.keys())[-1]\n",
    "            G = graphs[last_key]\n",
    "            pos = nx.spring_layout(G, k=0.2, seed=42)\n",
    "            node_colors = [\"pink\" if node == professor_search_parameter else \"lightgreen\" for node in G.nodes]\n",
    "\n",
    "            nx.draw(\n",
    "                G, pos, with_labels=True, node_color=node_colors, node_size=1500,\n",
    "                font_size=12, font_weight='normal', edge_color='gray', width=2,\n",
    "                alpha=0.7, edgecolors=\"black\"\n",
    "            )\n",
    "            \n",
    "            # Draw edge labels if available\n",
    "            edge_labels = nx.get_edge_attributes(G, 'weight')\n",
    "            nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=10)\n",
    "\n",
    "            #nt = Network(height=\"750px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\", select_menu=True, filter_menu=True)\n",
    "            nt = Network(height=\"750px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\")\n",
    "\n",
    "            nt.set_options(\"\"\"\n",
    "            const options = {\n",
    "                \"nodes\": {\n",
    "                    \"color\": {\n",
    "                        \"background\": \"lightgreen\",\n",
    "                        \"border\": \"white\",\n",
    "                        \"highlight\": {\n",
    "                            \"background\": \"pink\",\n",
    "                            \"border\": \"pink\"\n",
    "                        },\n",
    "                        \"hover\": {\n",
    "                            \"background\": \"yellow\",\n",
    "                            \"border\": \"white\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"font\": {\n",
    "                        \"color\": \"white\"\n",
    "                    }\n",
    "                },\n",
    "                \"edges\": {\n",
    "                    \"color\": {\n",
    "                        \"color\": \"gray\",\n",
    "                        \"highlight\": \"pink\"\n",
    "                    },\n",
    "                    \"width\": 2,\n",
    "                    \"smooth\": {\n",
    "                        \"type\": \"curvedCW\",\n",
    "                        \"roundness\": 0.2\n",
    "                    }\n",
    "                },\n",
    "                \"interaction\": {\n",
    "                    \"hover\": true,\n",
    "                    \"selectConnectedEdges\": true\n",
    "                },\n",
    "                \"physics\": {\n",
    "                    \"barnesHut\": {\n",
    "                        \"theta\": 0.35,\n",
    "                        \"damping\": 0.41,\n",
    "                        \"avoidOverlap\": 0.8\n",
    "                    },\n",
    "                    \"minVelocity\": 0.75\n",
    "                }\n",
    "            }\n",
    "            \"\"\")\n",
    "            nt.from_nx(G)        \n",
    "            nt.show(f'{category_search_parameter.replace(\" \", \"_\")}.html', notebook=False)\n",
    "\n",
    "            # Open the HTML file and modify its styles\n",
    "            with open(f'{category_search_parameter.replace(\" \", \"_\")}.html', 'r', encoding='utf-8') as f:\n",
    "                html = f.read()\n",
    "\n",
    "            # Remove any extra padding or margins around the graph container\n",
    "            html = html.replace(\n",
    "                '<body>',\n",
    "                '<body style=\"margin: 0; padding: 0; overflow: hidden;\">'\n",
    "            )\n",
    "\n",
    "            # Write the modified HTML back\n",
    "            with open('graph.html', 'w', encoding='utf-8') as f:\n",
    "                f.write(html)\n",
    "\n",
    "    elif search_professor:\n",
    "        professor_data = df[df.index == professor_search_parameter]\n",
    "\n",
    "        if not professor_data.empty:\n",
    "            related_professors = professor_data['related_professors'].values[0]\n",
    "            \n",
    "            G = nx.Graph()\n",
    "            G.add_node(professor_search_parameter)\n",
    "            added_nodes = {professor_search_parameter}\n",
    "            visited = set([professor_search_parameter])\n",
    "            \n",
    "            # Perform BFS for 1st, 2nd, and further layers\n",
    "            layer_queue = [(professor_search_parameter, related_professors)]  # (professor, related_professors)\n",
    "            \n",
    "            # For each layer, we'll expand the related professors\n",
    "            while layer_queue:\n",
    "                current_layer = layer_queue.pop(0)  # Get the next professor and their related professors\n",
    "                current_professor, related_professors = current_layer\n",
    "                \n",
    "                # Add all related professors from this layer\n",
    "                for related_professor, weight in related_professors:\n",
    "                    if min_weight > weight:\n",
    "                        continue\n",
    "                    if related_professor not in added_nodes:\n",
    "                        G.add_node(related_professor)\n",
    "                        G.add_edge(current_professor, related_professor, weight=weight)\n",
    "                        added_nodes.add(related_professor)\n",
    "                        visited.add(related_professor)  # Mark as visited\n",
    "\n",
    "                        # Add all related professors of the current professor to the queue for the next layer\n",
    "                        if related_professor in df.index:\n",
    "                            next_layer_professors = df.loc[related_professor, 'related_professors']\n",
    "\n",
    "                            if isinstance(next_layer_professors, float):\n",
    "                                continue\n",
    "\n",
    "                            # Only add to the queue if this professor hasn't been visited already\n",
    "                            for next_related_professor, _ in next_layer_professors:                            \n",
    "                                if next_related_professor not in visited:\n",
    "                                    layer_queue.append((related_professor, next_layer_professors))\n",
    "\n",
    "            pos = nx.spring_layout(G, k=0.2, seed=42)\n",
    "\n",
    "            node_colors = [\"pink\" if node == professor_search_parameter else \"lightgreen\" for node in G.nodes]\n",
    "\n",
    "            nx.draw(\n",
    "                G, pos, with_labels=True, node_color=node_colors, node_size=1500,\n",
    "                font_size=12, font_weight='normal', edge_color='gray', width=2,\n",
    "                alpha=0.7, edgecolors=\"black\"\n",
    "            )\n",
    "            \n",
    "            edge_labels = nx.get_edge_attributes(G, 'weight')\n",
    "            nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=10)\n",
    "\n",
    "        else:\n",
    "            print(f\"Professor '{professor_search_parameter}' not found in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(\n",
    "    df, \n",
    "    search_professor=False,\n",
    "    category_search_parameter=\"school\",\n",
    "    #professor_search_parameter=\"Christina Fuller\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
